{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bakery1000 = pd.read_csv('../apriori/1000/1000-out1.csv',sep = '\\n', header = None)\n",
    "bakery1000Mtemp = bakery1000.iloc[:,0].values\n",
    "bakery1000M = [list(map(int, x.split(','))) for x in bakery1000Mtemp]\n",
    "for x in bakery1000M:\n",
    "    del x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "goods = pd.read_csv('../apriori/goods.csv')\n",
    "goods['Flavor'] = goods['Flavor'] + \"-\" + goods['Food']\n",
    "goodsDict = dict(zip(goods['Id'], goods['Flavor']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exampleData = pd.read_csv('../example/out1.csv', sep = '\\n', header = None)\n",
    "exampleDataTemp = exampleData.iloc[:,0].values\n",
    "exampleDataM = [list(map(int, x.split(','))) for x in exampleDataTemp]\n",
    "for x in exampleDataM:\n",
    "    del x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def support(item, baskets):\n",
    "    top = sum([1 if item in basket else 0 for basket in baskets])\n",
    "    bottom = len(baskets)\n",
    "    return top*1.0/bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPairs(F, k):\n",
    "    outList = []\n",
    "    for first in F:\n",
    "        for second in F:\n",
    "            if len(first) == len(second) == k:\n",
    "                outList.append([first, second, tuple(set(first) | set(second))])\n",
    "    return outList "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSubsets(tmpTuple):\n",
    "    size = len(tmpTuple) - 1\n",
    "    return set(itertools.combinations(list(tmpTuple), size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def candidate(F,k):\n",
    "    C = set()\n",
    "    for pair in getPairs(F,k):\n",
    "        if len(pair[2]) == len(pair[0]) + 1:\n",
    "            c = pair[2]\n",
    "            flag = True\n",
    "            for s in getSubsets(c):\n",
    "                if s not in F:\n",
    "                    flag = False\n",
    "            if flag == True:\n",
    "                if c not in C:\n",
    "                    C.add(tuple(c))\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apriori(T, minSup):\n",
    "    FullSupport = []\n",
    "    I =  list(set(x for l in T for x in l))\n",
    "    Fk = []; Fk.append(None);\n",
    "    firstIter = set(tuple([x]) for x in filter(lambda a: a != -1, [x if support(x, T) >= minSup else -1 for x in I]))\n",
    "    Fk.append(firstIter)\n",
    "    k = 2\n",
    "    while len(Fk[k-1]) != 0:\n",
    "        print(\"running\")\n",
    "        Ck = candidate(Fk[k-1], k-1)\n",
    "        count = {}\n",
    "        for c in Ck:\n",
    "            count[c] = 0\n",
    "        for t in T:\n",
    "            for c in Ck:\n",
    "                if set(c) <= set(tuple(t)):\n",
    "                    count[c] += 1\n",
    "        tmpFk = []\n",
    "        for c in Ck:\n",
    "            if count[c]*1.0/len(T) >= minSup:\n",
    "                tmpFk.append(c)\n",
    "        Fk.append(set(tmpFk))\n",
    "        newSet = set(x for x in Fk[k-1])\n",
    "        for newTerm in Fk[k]:\n",
    "            for oldTerm in Fk[k-1]:\n",
    "                if set(oldTerm).issubset(newTerm) == True:\n",
    "                    if oldTerm in newSet:\n",
    "                        newSet.remove(oldTerm)\n",
    "                        #print(\"After: \", newSet)\n",
    "        Fk[k-1] = set(tuple(sorted(x)) for x in newSet)\n",
    "        k += 1\n",
    "    Fk = Fk[1:-1]\n",
    "    return Fk\n",
    "                    \n",
    "            \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCorrect():\n",
    "    t = np.linspace(.05, .01, 20)\n",
    "    for minS in t:\n",
    "        ap = addNamesFreq(apriori(bakery1000M, minS),goodsDict)\n",
    "        print(\"---- Apriori: \", minS, \" ----\")\n",
    "        print(\"NumRules: \", len(genRules(bakery1000M, ap, .85)))\n",
    "        for i, val in enumerate(ap):\n",
    "            print(i+1, \": \", len(val))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genRules(data, freqItemSet, minConf):\n",
    "    allRules = []\n",
    "    freqItemSet = freqItemSet[1:]\n",
    "    freqItemSet = [item for sublist in freqItemSet for item in sublist]\n",
    "    for itemSet in freqItemSet:\n",
    "        for item in itemSet:\n",
    "            noItem=set(itemSet)-(set([item]))\n",
    "            item = set([item])\n",
    "            conf = confidence(data,noItem,item)\n",
    "            sup = supportOut(data,noItem,item)\n",
    "            confItem = [noItem, item, conf, sup]\n",
    "            if conf >= minConf:\n",
    "                allRules.append(confItem)\n",
    "                \n",
    "            \n",
    "    return allRules\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence(T,set1,set2): #Dataset,leftSideList,rightSideList\n",
    "    top = sum([1 if (set1|set2) <= set(basket) else 0 for basket in T])\n",
    "    bottom = sum([1 if (set1) <= set(basket) else 0 for basket in T])\n",
    "    if(bottom == 0 | top == 0):\n",
    "        return 0\n",
    "    return top*1.0/bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supportOut(T, set1,set2):\n",
    "    return sum([1 if (set1|set2) <= set(basket) else 0 for basket in T])/len(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpOut = apriori(bakery1000M, .01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSupportFreq(T, output):\n",
    "    allFreq = []\n",
    "    for groupSize in output:\n",
    "        for term in groupSize:\n",
    "            termSup = supportOut(T, set(term), set([]))\n",
    "            termOut = [term,termSup]\n",
    "            allFreq.append(termOut)\n",
    "    return allFreq\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addNamesFreq(output, goods):\n",
    "    groupList=[]\n",
    "    for i, basket in enumerate(output):\n",
    "        basketList = []\n",
    "        for value in list(basket[0]):\n",
    "            basketList.append(goods[value])\n",
    "        groupList.append([basketList, basket[1]])\n",
    "    return groupList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addNames(output, goods):\n",
    "    ruleList = []\n",
    "    for i, rule in enumerate(output):\n",
    "        termList = []\n",
    "        for j, terms in enumerate(rule[:-2]):\n",
    "            setList = []\n",
    "            for k, objectId in enumerate(list(terms)):\n",
    "                setList.append(goods[objectId])\n",
    "            termList.append(setList)\n",
    "        termList.append(rule[2])\n",
    "        termList.append(rule[3])\n",
    "        ruleList.append(termList)\n",
    "    return ruleList  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printCorrectly(output):\n",
    "    for i, rule in enumerate(output):\n",
    "        print(\"Rule: \", i, '   ', ','.join(rule[0]), \" --> \", \n",
    "                rule[1][0]) \n",
    "        print(\"              Support: \", str(rule[3]))\n",
    "        print(\"              Confidence: \", str(rule[2]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findRules(T, minSup, minConf, goodsDictTmp, bakery = False):\n",
    "    aprioriOutput = apriori(T, minSup)\n",
    "    print(\"hi\")\n",
    "    aprioriNames = None\n",
    "    if(bakery == True):\n",
    "        aprioriNames = addNamesFreq(getSupportFreq(T, aprioriOutput), goodsDictTmp)\n",
    "        for i, itemSet in enumerate(aprioriNames):\n",
    "            print('Set # ', i+1, \" \", itemSet)\n",
    "    genRulesOutput = genRules(T, aprioriOutput, minConf)\n",
    "    if(bakery == True):\n",
    "        genRulesOutput = addNames(genRulesOutput, goodsDictTmp)\n",
    "    print(\"**********************************************\")\n",
    "    printCorrectly(genRulesOutput)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bakery5000 = pd.read_csv('../apriori/5000/5000-out1.csv',sep = '\\n', header = None)\n",
    "bakery5000Mtemp = bakery5000.iloc[:,0].values\n",
    "bakery5000M = [list(map(int, x.split(','))) for x in bakery5000Mtemp]\n",
    "for x in bakery5000M:\n",
    "    del x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMinSupport(dataSet,goodsDict):\n",
    "    t = np.linspace(.05, .01, 5)\n",
    "    for minSup in t:\n",
    "        print(\"******* \",minSup,\" *******\")\n",
    "        findRules(dataSet, minSup, .8, goodsDict, bakery=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bakery20000 = pd.read_csv('../apriori/20000/20000-out1.csv',sep = '\\n', header = None)\n",
    "bakery20000Mtemp = bakery20000.iloc[:,0].values\n",
    "bakery20000M = [list(map(int, x.split(','))) for x in bakery20000Mtemp]\n",
    "for x in bakery20000M:\n",
    "    del x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bakery75000 = pd.read_csv('../apriori/75000/75000-out1.csv',sep = '\\n', header = None)\n",
    "bakery75000Mtemp = bakery75000.iloc[:,0].values\n",
    "bakery75000M = [list(map(int, x.split(','))) for x in bakery75000Mtemp]\n",
    "for x in bakery75000M:\n",
    "    del x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bingoData = pd.read_csv('../apriori/bingoBaskets.csv',sep = '\\n', header = None)\n",
    "bingoData = bingoData.iloc[:,0].values\n",
    "bingoData = [list(map(int, x.split(','))) for x in bingoData]\n",
    "for x in bingoData:\n",
    "    del x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = pd.read_csv('../apriori/authors.psv',sep = '|', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#authors = authors[authors[1] != ' *N/A']\n",
    "authorsDict = dict(zip(list(authors[0]), list(authors[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#findRules(bingoData, .048, .8, authorsDict, bakery=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "basketFactors = pd.read_csv('../example/factor_baskets_sparse.csv',sep = '\\n', header = None)\n",
    "#bingoData = bingoData.iloc[:,0].values\n",
    "#bingoData = [list(map(int, x.split(','))) for x in bingoData]\n",
    "#for x in bingoData:\n",
    " #   del x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "baskets = basketFactors.iloc[1:,0].values\n",
    "baskets = [list(map(int, x.split(','))) for x in baskets]\n",
    "for x in baskets:\n",
    "    del x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "newBaskets = []\n",
    "for x in baskets:\n",
    "    t = x[::2]\n",
    "    newBaskets.append(t)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = pd.read_csv('../example/factors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "factorsDict = dict(zip(list(factors['tf_id']), list(factors['transfac'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpBaskets= newBaskets[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
